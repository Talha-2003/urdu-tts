{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedHanzala/urdu-voice-cloning/blob/main/notebooks/Training_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Z6kCeDNrdWM7",
        "outputId": "ab69f845-18ed-4c91-8029-581519e9be96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 16 14:23:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "metadata": {
        "id": "xFt4umCqjlS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/trainer/"
      ],
      "metadata": {
        "id": "sA2gX-TqaAnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/Gatozu35/tortoise-tts/resolve/main/dvae.pth -O experiments/dvae.pth\n",
        "!wget https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth -O experiments/autoregressive.pth\n",
        "!pip install -r codes/requirements.laxed.txt"
      ],
      "metadata": {
        "id": "_WFtZjtFbS9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Datset plug</h1>"
      ],
      "metadata": {
        "id": "BQTong_qj7sJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from math import ceil\n",
        "DEFAULT_TRAIN_BS = 64\n",
        "DEFAULT_VAL_BS = 32\n",
        "Dataset_Training_Path = \"/content/gdrive/MyDrive/junaid-akram-dataset/train.txt\"\n",
        "ValidationDataset_Training_Path = \"/content/gdrive/MyDrive/junaid-akram-dataset/val.txt\"\n",
        "\n",
        "\n",
        "#@markdown  `dataset/`\n",
        "#@markdown * ---├── `val.txt`\n",
        "#@markdown * ---├── `train.txt`\n",
        "#@markdown * ---├── `wavs/`\n",
        "\n",
        "#@markdown `wavs/` directory must contain `.wav` files.\n",
        "\n",
        "#@markdown  Example for `train.txt` and `val.txt`:\n",
        "\n",
        "#@markdown * `wavs/A.wav|Write the transcribed audio here.`\n",
        "\n",
        "\n",
        "if Dataset_Training_Path == ValidationDataset_Training_Path:\n",
        "  print(\"WARNING: training dataset path == validation dataset path!!!\")\n",
        "  print(\"\\tThis is technically okay but will make all of the validation metrics useless. \")\n",
        "  print(\"it will also SUBSTANTIALLY slow down the rate of training, because validation datasets are supposed to be much smaller than training ones.\")\n",
        "\n",
        "def txt_file_lines(p: str) -> int:\n",
        "  return len(Path(p).read_text().strip().split('\\n'))\n",
        "training_samples = txt_file_lines(Dataset_Training_Path)\n",
        "val_samples = txt_file_lines(ValidationDataset_Training_Path)\n",
        "\n",
        "if training_samples < 128: print(\"WARNING: very small dataset! the smallest dataset tested thus far had ~200 samples.\")\n",
        "if val_samples < 20: print(\"WARNING: very small validation dataset! val batch size will be scaled down to account\")\n",
        "\n",
        "def div_spillover(n: int, bs: int) -> int: # returns new batch size\n",
        "  epoch_steps,remain = divmod(n,bs)\n",
        "  if epoch_steps*2 > bs: return bs # don't bother optimising this stuff if epoch_steps are high\n",
        "  if not remain: return bs # unlikely but still\n",
        "\n",
        "  if remain*2 < bs: # \"easier\" to get rid of remainder -- should increase bs\n",
        "    target_bs = n//epoch_steps\n",
        "  else: # easier to increase epoch_steps by 1 -- decrease bs\n",
        "    target_bs = n//(epoch_steps+1)\n",
        "  assert n%target_bs < epoch_steps+2 # should be very few extra\n",
        "  return target_bs\n",
        "\n",
        "if training_samples < DEFAULT_TRAIN_BS:\n",
        "  print(\"WARNING: dataset is smaller than a single batch. This will almost certainly perform poorly. Trying anyway\")\n",
        "  train_bs = training_samples\n",
        "else:\n",
        "  train_bs = div_spillover(training_samples, DEFAULT_TRAIN_BS)\n",
        "if val_samples < DEFAULT_VAL_BS:\n",
        "  val_bs = val_samples\n",
        "else:\n",
        "  val_bs = div_spillover(val_samples, DEFAULT_VAL_BS)\n",
        "\n",
        "steps_per_epoch = training_samples//train_bs\n",
        "lr_decay_epochs = [20, 40, 56, 72]\n",
        "lr_decay_steps = [steps_per_epoch * e for e in lr_decay_epochs]\n",
        "print_freq = min(100, max(20, steps_per_epoch))\n",
        "val_freq = save_checkpoint_freq = print_freq * 3\n",
        "\n",
        "print(\"===CALCULATED SETTINGS===\")\n",
        "print(f'{train_bs=} {val_bs=}')\n",
        "print(f'{val_freq=} {lr_decay_steps=}')\n",
        "print(f'{print_freq=} {save_checkpoint_freq=}')"
      ],
      "metadata": {
        "id": "lQQC93cjfmNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad1978e-055b-4191-f8a7-0994ed3eccab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===CALCULATED SETTINGS===\n",
            "train_bs=64 val_bs=32\n",
            "val_freq=300 lr_decay_steps=[3500, 7000, 9800, 12600]\n",
            "print_freq=100 save_checkpoint_freq=300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Hyper Parameters</h1>"
      ],
      "metadata": {
        "id": "YyvJ0-Wh3-A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4IFgHn8rmMW",
        "outputId": "0ffca670-4a0b-40ec-fb6d-810ef296a0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1JbZPHBYVAP3fNSd0qIC-BTuok5kUH1WQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Experiment_Name = \"junaid-akram-clone\"\n",
        "Dataset_Training_Name= \"junaid-akram-clone\"\n",
        "ValidationDataset_Name = \"TestValidation\"\n",
        "SaveTrainingStates = False\n",
        "Keep_Last_N_Checkpoints = 1\n",
        "\n",
        "Fp16 = False\n",
        "Use8bit = True\n",
        "TrainingRate = \"1e-5\"\n",
        "TortoiseCompat = True\n",
        "\n",
        "\n",
        "\n",
        "TrainBS = \"\"\n",
        "ValBS = \"\"\n",
        "ValFreq = \"\"\n",
        "LRDecaySteps = \"\"\n",
        "PrintFreq = \"\"\n",
        "SaveCheckpointFreq = \"\"\n",
        "\n",
        "def take(orig, override):\n",
        "  if override == \"\": return orig\n",
        "  return type(orig)(override)\n",
        "\n",
        "train_bs = take(train_bs, TrainBS)\n",
        "val_bs = take(val_bs, ValBS)\n",
        "val_freq = take(val_freq, ValFreq)\n",
        "lr_decay_steps = eval(LRDecaySteps) if LRDecaySteps else lr_decay_steps\n",
        "print_freq = take(print_freq, PrintFreq)\n",
        "save_checkpoint_freq = take(save_checkpoint_freq, SaveCheckpointFreq)\n",
        "assert len(lr_decay_steps) == 4\n",
        "gen_lr_steps = ', '.join(str(v) for v in lr_decay_steps)\n",
        "\n",
        "\n",
        "\n",
        "%cd trainer\n",
        "!wget https://raw.githubusercontent.com/152334H/trainer/master/experiments/EXAMPLE_gpt.yml -O experiments/EXAMPLE_gpt.yml\n",
        "\n",
        "import os\n",
        "!sed -i 's/batch_size: 128/batch_size: '\"$train_bs\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/batch_size: 64/batch_size: '\"$val_bs\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/val_freq: 500/val_freq: '\"$val_freq\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/500, 1000, 1400, 1800/'\"$gen_lr_steps\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/print_freq: 100/print_freq: '\"$print_freq\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/save_checkpoint_freq: 500/save_checkpoint_freq: '\"$save_checkpoint_freq\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "\n",
        "!sed -i 's+CHANGEME_validation_dataset_name+'\"$ValidationDataset_Name\"'+g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's+CHANGEME_path_to_validation_dataset+'\"$ValidationDataset_Training_Path\"'+g' ./experiments/EXAMPLE_gpt.yml\n",
        "if(Fp16==True):\n",
        "  os.system(\"sed -i 's+fp16: false+fp16: true+g' ./experiments/EXAMPLE_gpt.yml\")\n",
        "!sed -i 's/use_8bit: true/use_8bit: '\"$Use8bit\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "\n",
        "!sed -i 's/disable_state_saving: true/disable_state_saving: '\"$SaveTrainingStates\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/tortoise_compat: True/tortoise_compat: '\"$TortoiseCompat\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/number_of_checkpoints_to_save: 0/number_of_checkpoints_to_save: '\"$Keep_Last_N_Checkpoints\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "\n",
        "\n",
        "!sed -i 's/CHANGEME_training_dataset_name/'\"$Dataset_Training_Name\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's/CHANGEME_your_experiment_name/'\"$Experiment_Name\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
        "!sed -i 's+CHANGEME_path_to_training_dataset+'\"$Dataset_Training_Path\"'+g' ./experiments/EXAMPLE_gpt.yml\n",
        "\n",
        "\n",
        "if (not TrainingRate==\"1e-5\"):\n",
        "  os.system(\"sed -i 's+!!float 1e-5 # CHANGEME:+!!float '\" + TrainingRate + \"' #+g' ./experiments/EXAMPLE_gpt.yml\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ryVeEXfxqw3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Ay0tYbU8DUTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd codes\n",
        "\n",
        "!python3 train.py -opt ../experiments/EXAMPLE_gpt.yml"
      ],
      "metadata": {
        "id": "ju5yCN_m51r7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}